# DOOFSTROM
* Reads your hand signs and translates them to English words and voice output using Tensorflow object detection.<br/>
* The model is built using transfer learning from pretrained model ssd_mobilenet model.<br/>
* The dataset is made manually by running the **Image Collection python file** that collects images from the webcam for all the signs in the Indian Sign Language. 

The model was made only with help of Nicholas Renotte tutorial.

## LOGIN_PAGE:

![image](https://user-images.githubusercontent.com/104593776/197589254-91674047-65b7-466d-8d95-d6d4b391098f.png)



## VIDEO_CALL:
                                                                      DEMO
                                                 
                                                 
 

https://user-images.githubusercontent.com/104593776/197756920-9334f50b-a573-4764-bf5c-b306e498337a.mp4

          



